{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'python',\n",
       " 'or',\n",
       " 'm.l.',\n",
       " 'i',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对于一个文本字符串，可以使用Python的string.split()方法将其切分\n",
    "mySent = 'This book is the best book on python or M.L. I have ever laid eyes upon'\n",
    "words = mySent.split(' ')\n",
    "#Python中有一些内嵌的方法，可以将字符串全部转换成小写（.lower()）或者大写（.upper()）\n",
    "[a.lower() for a in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anzhuang\\anaconda\\lib\\re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'python',\n",
       " 'or',\n",
       " 'm',\n",
       " 'l',\n",
       " 'i',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#上面标点符号也被当成了词的一部分。可以使用正则表达式来切分句子，其中分隔符是除单词、数字外的任意字符串\n",
    "import re\n",
    "words = re.split(r'\\W*',mySent)\n",
    "[a.lower() for a in words if len(a)>0 ]#只返回长度大于0的字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝叶斯相关函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建词表\n",
    "def vocabularyTable(dataSet):\n",
    "    vocabSet = set([])\n",
    "    for document in dataSet:\n",
    "        vocabSet = vocabSet | set(document)\n",
    "    return list(vocabSet)\n",
    "\n",
    "#构建词向量\n",
    "def doc2vec(vocabSet,document):\n",
    "    docVec = [0]*len(vocabSet)\n",
    "    for word in document:\n",
    "        if (word in vocabSet):\n",
    "            docVec[vocabSet.index(word)] = 1\n",
    "    return docVec   \n",
    "\n",
    "#训练贝叶斯分类器\n",
    "import numpy as np\n",
    "import math\n",
    "def trainBayes(trainVec,classLabel):\n",
    "    numData = len(trainVec)\n",
    "    numWords = len(trainVec[0])\n",
    "    pAbusive = sum(classLabel)/float(numData)\n",
    "    p0num = np.ones(numWords); p1num = np.ones(numWords)\n",
    "    p0sum = 2; p1sum = 2\n",
    "    p1Vect =np.array([0]*numWords); p0Vect = np.array([0]*numWords)\n",
    "    for i in range(numData):\n",
    "        if(classLabel[i]==1):\n",
    "            p1num += trainVec[i]\n",
    "            p1sum += sum(trainVec[i])\n",
    "        else:\n",
    "            p0num += trainVec[i]\n",
    "            p0sum += sum(trainVec[i])\n",
    "    for i in range(numWords):\n",
    "        p1Vect[i] = math.log(p1num[i]/p1sum)\n",
    "        p0Vect[i] = math.log(p0num[i]/p0sum)\n",
    "    return pAbusive,p1Vect,p0Vect\n",
    "\n",
    "#贝叶斯分类函数\n",
    "def classify(docVec,pClass1,p1Vect,p0Vect):\n",
    "    p1 = sum(docVec * p1Vect)+math.log(pClass1)\n",
    "    p0 = sum(docVec *p0Vect) +math.log(1-pClass1)\n",
    "    if(p1>p0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.文件解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textParse(email):\n",
    "    import re\n",
    "    words = re.split(r'\\W*',email)\n",
    "    return [a.lower() for a in words if(len(a)>2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spamTest():\n",
    "    docList = []; classList = []\n",
    "    for i in range(1,26):\n",
    "        wordList = textParse(open('email/spam/%d.txt'%i).read())\n",
    "        docList.append(wordList)\n",
    "        classList.append(1)\n",
    "        wordList = textParse(open('email/ham/%d.txt'%i).read())\n",
    "        docList.append(wordList)\n",
    "        classList.append(0)\n",
    "    vocabList = vocabularyTable(docList)\n",
    "    \n",
    "    #随机抽取10封邮件用来测试\n",
    "    trainingSet = list(range(50)); testSet = []\n",
    "    for i in range(10):\n",
    "        #这地方不能用50，只能用len(trainingSet),因为删除一个元素之后只有49个元素了，\n",
    "        #索引最大值为48，下一次循环若生成的随机数为49则超过了索引\n",
    "        randIndex = int(np.random.uniform(0,len(trainingSet)))\n",
    "        testSet.append(trainingSet[randIndex])\n",
    "        del(trainingSet[randIndex])\n",
    "    trainMat = []; trainClass = []\n",
    "    for index in trainingSet:\n",
    "        trainMat.append(doc2vec(vocabList,docList[index]))\n",
    "        trainClass.append(classList[index])\n",
    "    #训练\n",
    "    pSpam,p1Vect,p0Vect = trainBayes(trainMat,trainClass)\n",
    "    #测试\n",
    "    errorCount = 0\n",
    "    for index in testSet:\n",
    "        wordVect = doc2vec(vocabList,docList[index])\n",
    "        if(classify(np.array(wordVect),pSpam,p1Vect,p0Vect)!= classList[index]):\n",
    "            errorCount+=1\n",
    "            print('the real class is %d,the predict class is %d'%(classList[index],classify(np.array(wordVect),pSpam,p1Vect,p0Vect)))\n",
    "            print(docList[index])    \n",
    "    print('the erroe rate is %.2f'%(float(errorCount)/len(testSet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the real class is 1,the predict class is 0\n",
      "['home', 'based', 'business', 'opportunity', 'knocking', 'your', 'door', 'don抰', 'rude', 'and', 'let', 'this', 'chance', 'you', 'can', 'earn', 'great', 'income', 'and', 'find', 'your', 'financial', 'life', 'transformed', 'learn', 'more', 'here', 'your', 'success', 'work', 'from', 'home', 'finder', 'experts']\n",
      "the erroe rate is 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anzhuang\\anaconda\\lib\\re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "spamTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
